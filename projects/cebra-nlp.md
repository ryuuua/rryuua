---
layout: page
title: CEBRA NLP
permalink: /projects/cebra-nlp/
---

## 概要
非線形ICAフレームワークである CEBRA を自然言語の表現学習に応用し、埋め込み空間に潜む低次元構造や意味軸を抽出する研究プロジェクト。多様なコントラスト変数（文脈・スタイル・タスクラベル等）を組み合わせ、安定した非線形復元と可視化を目指す。

## 研究背景
- 既存のLLM埋め込みは高次元かつブラックボックスで、下流タスクへの転移指標が解釈困難。
- CEBRAは時系列・神経活動解析で高評価を得たが、自然言語への応用事例は少ない。
- 非線形ICAを活かし、言語理解に有用な潜在態を抽出することで、分析・制御・対話エージェントの頑健性向上を狙う。

## 目的
- 文脈変数を取り込んだ CEbra objective の再設計と安定化。
- 低次元潜在軸の解釈性検証（意味カテゴリ、スタイル、感情など）。
- 研究ログや再現コードを公開し、追試可能な解析パイプラインを整備。

## 手法
1. 各種事前学習済み言語モデル（BERT, GPT系など）からトークン/文埋め込みを抽出。
2. センチメント、話者属性、ジャンルといった補助変数を対比学習のキーとして利用。
3. フォワードモデルと逆写像を比較し、潜在空間の安定性と識別性能を評価。
4. UMAP/CEBRAプロットや最近傍解析を組み合わせ、潜在軸の意味付けを行う。

## データセット
- GLUE ベンチマーク（Sentiment / NLI）
- MultiNLI, SST-2, Yelp Review などラベル付きテキスト
- Wikipedia / CC-News の自己教師タスクによる補助信号

## 進行状況
- [x] 文埋め込み抽出と前処理基盤を整備
- [x] CEBRA 損失の実装と安定化ハイパーパラメータの探索
- [ ] ラベル付きデータでの潜在軸評価（線形分類器・クラスタリング）
- [ ] マルチモーダル条件（音声トランスクリプト等）との統合実験
- [ ] 研究ノート・可視化ダッシュボードの公開

## 成果物
- コードリポジトリ（準備中）
- 実験レポートと可視化スナップショット（private notion → 公開予定）
- 学会投稿論文: "Low-dimensional structure in language embeddings via CEBRA"（執筆中）

## 次のステップ
- 低リソース言語での一般化性能を測る追加実験
- 統計的独立性の尺度に基づく潜在軸の自動解釈アルゴリズム
- 共同研究者募集（特にマルチモーダル対話・情報可視化に強い方）
